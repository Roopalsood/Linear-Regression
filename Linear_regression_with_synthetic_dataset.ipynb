{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPYIHA1pgT6hWdDIzn6g2kP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Roopalsood/Linear-Regression-with-Synthetic-Data-Machine-Learning-Foundational-Google/blob/main/Linear_regression_with_synthetic_dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "ELWkm5Pp_5mI"
      },
      "outputs": [],
      "source": [
        "#A Machine Learning Model for a synthetic dataset form Machine Learning Course by Google.\n",
        "\n",
        "#A process in which new data is created by either manually using tools like Excel or automatically using computer simulations or \n",
        "#algorithms as a substitute for real-world data is called synthetic data generation."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#importing all the required modules\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from matplotlib import pyplot as plt"
      ],
      "metadata": {
        "id": "IkzJ5V2dAQYi"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#building the model\n",
        "# we are using sequential model here. Its the simplest of all models using keras\n",
        "# we define the topology of the model\n",
        "# we tend to minimize the Rootmeansquare error in the model so we optimize it\n",
        "def build_model(my_learning_rate):\n",
        "  \n",
        "  model = tf.keras.models.Sequential()\n",
        "\n",
        "  model.add(tf.keras.layers.Dense(units=1, \n",
        "                                  input_shape=(1,)))\n",
        "\n",
        "  \n",
        "  model.compile(optimizer=tf.keras.optimizers.experimental.RMSprop(learning_rate=my_learning_rate),\n",
        "                loss=\"mean_squared_error\",\n",
        "                metrics=[tf.keras.metrics.RootMeanSquaredError()])\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "bIaxNKDmBb-o"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "0#training the model\n",
        "#specifying the epochs, the model will learn all the features and relate them to label values.\n",
        "#hist is to get the dataframe of the model\n",
        "\n",
        "\n",
        "def train_model(model, feature, label, epochs, batch_size):\n",
        "  \"\"\"Train the model by feeding it data.\"\"\"\n",
        "\n",
        "\n",
        "  history = model.fit(x=feature,\n",
        "                      y=label,\n",
        "                      batch_size=batch_size,\n",
        "                      epochs=epochs)\n",
        "\n",
        "  \n",
        "  trained_weight = model.get_weights()[0]\n",
        "  trained_bias = model.get_weights()[1]\n",
        "\n",
        " \n",
        "  epochs = history.epoch\n",
        "  \n",
        "\n",
        "  hist = pd.DataFrame(history.history)\n",
        "\n",
        "\n",
        "  rmse = hist[\"root_mean_squared_error\"]\n",
        "\n",
        "  return trained_weight, trained_bias, epochs, rmse\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "AktIgj6bEVrV"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plotting the curve using matplotlib library\n",
        "#defining labels for x and y axis\n",
        "# the line is in color blue\n",
        "\n",
        "def plot_the_model(trained_weight, trained_bias, feature, label):\n",
        "\n",
        "  plt.xlabel(\"feature\")\n",
        "  plt.ylabel(\"label\")\n",
        "\n",
        " \n",
        "  plt.scatter(feature, label)\n",
        "\n",
        "\n",
        "  x0 = 0\n",
        "  y0 = trained_bias\n",
        "  x1 = feature[-1]\n",
        "  y1 = trained_bias + (trained_weight * x1)\n",
        "  plt.plot([x0, x1], [y0, y1], c='r')\n",
        "\n",
        "\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "print(\"Function to show the plot is defined\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QSqNnlzSGbI-",
        "outputId": "60d4eb8a-8698-4f66-c37d-7608875b1ec0"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Function to show the plot is defined\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#given the synthetic data for feature and label\n",
        "\n",
        "my_feature = ([1.0, 2.0,  3.0,  4.0,  5.0,  6.0,  7.0,  8.0,  9.0, 10.0, 11.0, 12.0])\n",
        "my_label   = ([5.0, 8.8,  9.6, 14.2, 18.8, 19.5, 21.4, 26.8, 28.9, 32.0, 33.8, 38.2])"
      ],
      "metadata": {
        "id": "gTp_nK7AIC2a"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#providing with hyperparameters\n",
        "#initialising the function build model then train model\n",
        "# since the return value of train model function are trained_weight, traineed_bias, epochs, rmse, \n",
        "# we simply put it as equals to the model functin when we call it and the values get allocated respectively\n",
        "# we simply plot the graph of the model\n",
        "\n",
        "learning_rate=0.05\n",
        "epochs=125\n",
        "my_batch_size=1 \n",
        "\n",
        "my_model = build_model(learning_rate)\n",
        "trained_weight, trained_bias, epochs, rmse = train_model(my_model, my_feature, \n",
        "                                                         my_label, epochs,\n",
        "                                                         my_batch_size)\n",
        "\n",
        "plot_the_model(trained_weight, trained_bias, my_feature, my_label)\n",
        "\n",
        "\n",
        "print(\"Above is the plot of the model\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "GUTpvGMtIgnZ",
        "outputId": "cc3a3dbf-18ca-4569-fe32-07c179e987aa"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/125\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 84.5099 - root_mean_squared_error: 9.1929\n",
            "Epoch 2/125\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 27.1173 - root_mean_squared_error: 5.2074\n",
            "Epoch 3/125\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 7.0380 - root_mean_squared_error: 2.6529\n",
            "Epoch 4/125\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.5614 - root_mean_squared_error: 1.2496\n",
            "Epoch 5/125\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.0811 - root_mean_squared_error: 1.0398\n",
            "Epoch 6/125\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.9438 - root_mean_squared_error: 0.9715\n",
            "Epoch 7/125\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.2098 - root_mean_squared_error: 1.0999\n",
            "Epoch 8/125\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.2442 - root_mean_squared_error: 1.1154\n",
            "Epoch 9/125\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.1814 - root_mean_squared_error: 1.0869\n",
            "Epoch 10/125\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.0684 - root_mean_squared_error: 1.0336\n",
            "Epoch 11/125\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.0565 - root_mean_squared_error: 1.0279\n",
            "Epoch 12/125\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.3291 - root_mean_squared_error: 1.1529\n",
            "Epoch 13/125\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.2178 - root_mean_squared_error: 1.1036\n",
            "Epoch 14/125\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.1651 - root_mean_squared_error: 1.0794\n",
            "Epoch 15/125\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.1443 - root_mean_squared_error: 1.0697\n",
            "Epoch 16/125\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.1548 - root_mean_squared_error: 1.0746\n",
            "Epoch 17/125\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.0036 - root_mean_squared_error: 1.0018\n",
            "Epoch 18/125\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.2366 - root_mean_squared_error: 1.1120\n",
            "Epoch 19/125\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.1215 - root_mean_squared_error: 1.0590\n",
            "Epoch 20/125\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.2284 - root_mean_squared_error: 1.1083\n",
            "Epoch 21/125\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.2181 - root_mean_squared_error: 1.1037\n",
            "Epoch 22/125\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.1976 - root_mean_squared_error: 1.0943\n",
            "Epoch 23/125\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.1983 - root_mean_squared_error: 1.0947\n",
            "Epoch 24/125\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.0594 - root_mean_squared_error: 1.0293\n",
            "Epoch 25/125\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.2467 - root_mean_squared_error: 1.1166\n",
            "Epoch 26/125\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.1857 - root_mean_squared_error: 1.0889\n",
            "Epoch 27/125\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.2342 - root_mean_squared_error: 1.1110\n",
            "Epoch 28/125\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.1779 - root_mean_squared_error: 1.0853\n",
            "Epoch 29/125\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.2214 - root_mean_squared_error: 1.1052\n",
            "Epoch 30/125\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.2454 - root_mean_squared_error: 1.1160\n",
            "Epoch 31/125\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.1402 - root_mean_squared_error: 1.0678\n",
            "Epoch 32/125\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.0358 - root_mean_squared_error: 1.0178\n",
            "Epoch 33/125\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.0839 - root_mean_squared_error: 1.0411\n",
            "Epoch 34/125\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.1070 - root_mean_squared_error: 1.0521\n",
            "Epoch 35/125\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.1514 - root_mean_squared_error: 1.0730\n",
            "Epoch 36/125\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.7467 - root_mean_squared_error: 0.8641\n",
            "Epoch 37/125\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.2370 - root_mean_squared_error: 1.1122\n",
            "Epoch 38/125\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.1657 - root_mean_squared_error: 1.0797\n",
            "Epoch 39/125\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.2180 - root_mean_squared_error: 1.1036\n",
            "Epoch 40/125\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.1393 - root_mean_squared_error: 1.0674\n",
            "Epoch 41/125\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.0889 - root_mean_squared_error: 1.0435\n",
            "Epoch 42/125\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1377 - root_mean_squared_error: 1.0667\n",
            "Epoch 43/125\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.1777 - root_mean_squared_error: 1.0852\n",
            "Epoch 44/125\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.2079 - root_mean_squared_error: 1.0990\n",
            "Epoch 45/125\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.1102 - root_mean_squared_error: 1.0537\n",
            "Epoch 46/125\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.2110 - root_mean_squared_error: 1.1005\n",
            "Epoch 47/125\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.0643 - root_mean_squared_error: 1.0317\n",
            "Epoch 48/125\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.2554 - root_mean_squared_error: 1.1204\n",
            "Epoch 49/125\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1425 - root_mean_squared_error: 1.0689\n",
            "Epoch 50/125\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.1487 - root_mean_squared_error: 1.0718\n",
            "Epoch 51/125\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.1569 - root_mean_squared_error: 1.0756\n",
            "Epoch 52/125\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.1077 - root_mean_squared_error: 1.0525\n",
            "Epoch 53/125\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.2240 - root_mean_squared_error: 1.1064\n",
            "Epoch 54/125\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.1842 - root_mean_squared_error: 1.0882\n",
            "Epoch 55/125\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.0734 - root_mean_squared_error: 1.0360\n",
            "Epoch 56/125\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.0962 - root_mean_squared_error: 1.0470\n",
            "Epoch 57/125\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1452 - root_mean_squared_error: 1.0702\n",
            "Epoch 58/125\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.1052 - root_mean_squared_error: 1.0513\n",
            "Epoch 59/125\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.0501 - root_mean_squared_error: 1.0247\n",
            "Epoch 60/125\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.2473 - root_mean_squared_error: 1.1168\n",
            "Epoch 61/125\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.0549 - root_mean_squared_error: 1.0271\n",
            "Epoch 62/125\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.1260 - root_mean_squared_error: 1.0611\n",
            "Epoch 63/125\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.1124 - root_mean_squared_error: 1.0547\n",
            "Epoch 64/125\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.1663 - root_mean_squared_error: 1.0800\n",
            "Epoch 65/125\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.3221 - root_mean_squared_error: 1.1498\n",
            "Epoch 66/125\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.9196 - root_mean_squared_error: 0.9590\n",
            "Epoch 67/125\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.2240 - root_mean_squared_error: 1.1064\n",
            "Epoch 68/125\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.0179 - root_mean_squared_error: 1.0089\n",
            "Epoch 69/125\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.0746 - root_mean_squared_error: 1.0366\n",
            "Epoch 70/125\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.1311 - root_mean_squared_error: 1.0636\n",
            "Epoch 71/125\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.2364 - root_mean_squared_error: 1.1119\n",
            "Epoch 72/125\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.0527 - root_mean_squared_error: 1.0260\n",
            "Epoch 73/125\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.2363 - root_mean_squared_error: 1.1119\n",
            "Epoch 74/125\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.1838 - root_mean_squared_error: 1.0880\n",
            "Epoch 75/125\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.9446 - root_mean_squared_error: 0.9719\n",
            "Epoch 76/125\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.0252 - root_mean_squared_error: 1.0125\n",
            "Epoch 77/125\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.2802 - root_mean_squared_error: 1.1314\n",
            "Epoch 78/125\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.1920 - root_mean_squared_error: 1.0918\n",
            "Epoch 79/125\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.1994 - root_mean_squared_error: 1.0952\n",
            "Epoch 80/125\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.2251 - root_mean_squared_error: 1.1069\n",
            "Epoch 81/125\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.1151 - root_mean_squared_error: 1.0560\n",
            "Epoch 82/125\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.2235 - root_mean_squared_error: 1.1061\n",
            "Epoch 83/125\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.2518 - root_mean_squared_error: 1.1189\n",
            "Epoch 84/125\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0111 - root_mean_squared_error: 1.0055\n",
            "Epoch 85/125\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.0973 - root_mean_squared_error: 1.0475\n",
            "Epoch 86/125\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.2562 - root_mean_squared_error: 1.1208\n",
            "Epoch 87/125\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1286 - root_mean_squared_error: 1.0624\n",
            "Epoch 88/125\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.0225 - root_mean_squared_error: 1.0112\n",
            "Epoch 89/125\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.9655 - root_mean_squared_error: 0.9826\n",
            "Epoch 90/125\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.3255 - root_mean_squared_error: 1.1513\n",
            "Epoch 91/125\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.2531 - root_mean_squared_error: 1.1194\n",
            "Epoch 92/125\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.2149 - root_mean_squared_error: 1.1022\n",
            "Epoch 93/125\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1837 - root_mean_squared_error: 1.0880\n",
            "Epoch 94/125\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.2440 - root_mean_squared_error: 1.1153\n",
            "Epoch 95/125\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.2023 - root_mean_squared_error: 1.0965\n",
            "Epoch 96/125\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.2183 - root_mean_squared_error: 1.1037\n",
            "Epoch 97/125\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.1878 - root_mean_squared_error: 1.0899\n",
            "Epoch 98/125\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.1507 - root_mean_squared_error: 1.0727\n",
            "Epoch 99/125\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.1919 - root_mean_squared_error: 1.0917\n",
            "Epoch 100/125\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.3040 - root_mean_squared_error: 1.1419\n",
            "Epoch 101/125\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.0300 - root_mean_squared_error: 1.0149\n",
            "Epoch 102/125\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.3215 - root_mean_squared_error: 1.1496\n",
            "Epoch 103/125\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.2263 - root_mean_squared_error: 1.1074\n",
            "Epoch 104/125\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.2753 - root_mean_squared_error: 1.1293\n",
            "Epoch 105/125\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.1276 - root_mean_squared_error: 1.0619\n",
            "Epoch 106/125\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.2129 - root_mean_squared_error: 1.1013\n",
            "Epoch 107/125\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.8718 - root_mean_squared_error: 0.9337\n",
            "Epoch 108/125\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.3197 - root_mean_squared_error: 1.1488\n",
            "Epoch 109/125\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.0776 - root_mean_squared_error: 1.0381\n",
            "Epoch 110/125\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.2186 - root_mean_squared_error: 1.1039\n",
            "Epoch 111/125\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.1273 - root_mean_squared_error: 1.0617\n",
            "Epoch 112/125\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.1260 - root_mean_squared_error: 1.0611\n",
            "Epoch 113/125\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.2281 - root_mean_squared_error: 1.1082\n",
            "Epoch 114/125\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.1020 - root_mean_squared_error: 1.0498\n",
            "Epoch 115/125\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.9849 - root_mean_squared_error: 0.9924\n",
            "Epoch 116/125\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.1671 - root_mean_squared_error: 1.0803\n",
            "Epoch 117/125\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.8557 - root_mean_squared_error: 0.9250\n",
            "Epoch 118/125\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.2040 - root_mean_squared_error: 1.0973\n",
            "Epoch 119/125\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.0834 - root_mean_squared_error: 1.0409\n",
            "Epoch 120/125\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.0594 - root_mean_squared_error: 1.0293\n",
            "Epoch 121/125\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.0814 - root_mean_squared_error: 1.0399\n",
            "Epoch 122/125\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.2360 - root_mean_squared_error: 1.1118\n",
            "Epoch 123/125\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.8976 - root_mean_squared_error: 0.9474\n",
            "Epoch 124/125\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.2963 - root_mean_squared_error: 1.1386\n",
            "Epoch 125/125\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.1854 - root_mean_squared_error: 1.0888\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/numpy/core/shape_base.py:65: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  ary = asanyarray(ary)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Above is the plot of the model\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UJoryygsP7ms"
      },
      "execution_count": 59,
      "outputs": []
    }
  ]
}